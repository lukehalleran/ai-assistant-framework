#max runb profile
SHELL := /bin/bash
PYTHON ?= python

RUN_ENV = \
	# Experiment: increase prompt section caps per request
	PROMPT_MAX_RECENT=10 \
	PROMPT_MAX_MEMS=20 \
	PROMPT_MAX_SEMANTIC=12 \
	PROMPT_MAX_FACTS=15 \
	PROMPT_MAX_SUMMARIES=10 \
	PROMPT_MAX_REFLECTIONS=5 \
	PROMPT_TOKEN_BUDGET=7168 \
	MODEL_MAX_TOKENS=7168 \
	RESERVE_FOR_COMPLETION=1024 \
	SUMMARY_EVERY_N=12 \
	REFLECTIONS_ENABLED=1 \
	REFLECTION_MAX_TOKENS=640 \
	REFLECTION_MIN_EXCHANGES=3 \
	REFLECTIONS_EVERY_N=10 \
	LLM_REFLECTION_ALIAS=gpt-4o-mini \
	LLM_SUMMARY_ALIAS=gpt-4o-mini \
	ENABLE_MIDDLE_OUT=0 \
	PROMPT_SHOW_EMPTY_SECTIONS=0 \
	WIKI_TIMEOUT=1.5 \
	WIKI_DISABLE_EMBED_SCORING=0 \
	SEM_TIMEOUT_S=7.0 \
	GATE_COSINE_THRESHOLD=0.45 \
	GATE_EMBED_BATCH=512 \
	CHROMA_DEVICE=cuda

RUN_CMD = env $(RUN_ENV)

.PHONY: run pipeline

run:
	@echo "Starting Daemon (max fidelity profile)..."
	@$(RUN_CMD) $(PYTHON) main.py

pipeline:
	@echo "Running pipeline (max fidelity profile)..."
	@$(RUN_CMD) $(PYTHON) data/pipeline/unified_pipeline.py --download --semantic --max-articles=1000 --chunk-size=1200 --chunk-overlap=200
